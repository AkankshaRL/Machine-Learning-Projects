{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e0a40c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-30T14:51:59.763690Z",
     "iopub.status.busy": "2024-06-30T14:51:59.763149Z",
     "iopub.status.idle": "2024-06-30T14:51:59.781332Z",
     "shell.execute_reply": "2024-06-30T14:51:59.780041Z"
    },
    "papermill": {
     "duration": 0.041032,
     "end_time": "2024-06-30T14:51:59.784556",
     "exception": false,
     "start_time": "2024-06-30T14:51:59.743524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476d29a",
   "metadata": {
    "papermill": {
     "duration": 0.01435,
     "end_time": "2024-06-30T14:51:59.815379",
     "exception": false,
     "start_time": "2024-06-30T14:51:59.801029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ca09be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:51:59.850974Z",
     "iopub.status.busy": "2024-06-30T14:51:59.850494Z",
     "iopub.status.idle": "2024-06-30T14:52:09.107212Z",
     "shell.execute_reply": "2024-06-30T14:52:09.105806Z"
    },
    "papermill": {
     "duration": 9.278978,
     "end_time": "2024-06-30T14:52:09.111047",
     "exception": false,
     "start_time": "2024-06-30T14:51:59.832069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Tensorflow and keras\n",
    "#Keras is built into TF 2.0\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "#Setting the Theme of the data visualizer Seaborn\n",
    "sns.set(style=\"dark\",context=\"notebook\",palette=\"muted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1858c",
   "metadata": {
    "papermill": {
     "duration": 0.014943,
     "end_time": "2024-06-30T14:52:09.141430",
     "exception": false,
     "start_time": "2024-06-30T14:52:09.126487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaa5498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:09.174337Z",
     "iopub.status.busy": "2024-06-30T14:52:09.173454Z",
     "iopub.status.idle": "2024-06-30T14:52:16.484604Z",
     "shell.execute_reply": "2024-06-30T14:52:16.483193Z"
    },
    "papermill": {
     "duration": 7.33134,
     "end_time": "2024-06-30T14:52:16.487860",
     "exception": false,
     "start_time": "2024-06-30T14:52:09.156520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"../input/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19594042",
   "metadata": {
    "papermill": {
     "duration": 0.014246,
     "end_time": "2024-06-30T14:52:16.517330",
     "exception": false,
     "start_time": "2024-06-30T14:52:16.503084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885b3839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:16.550063Z",
     "iopub.status.busy": "2024-06-30T14:52:16.549573Z",
     "iopub.status.idle": "2024-06-30T14:52:16.982390Z",
     "shell.execute_reply": "2024-06-30T14:52:16.981125Z"
    },
    "papermill": {
     "duration": 0.4531,
     "end_time": "2024-06-30T14:52:16.985480",
     "exception": false,
     "start_time": "2024-06-30T14:52:16.532380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train['label']\n",
    "\n",
    "#Dropping Label Column\n",
    "X_train = train.drop(labels=['label'],axis=1)\n",
    "\n",
    "#free up some space\n",
    "del train\n",
    "\n",
    "graph = sns.countplot(Y_train)\n",
    " \n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40889f72",
   "metadata": {
    "papermill": {
     "duration": 0.015943,
     "end_time": "2024-06-30T14:52:17.016894",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.000951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "1. **Extracting Labels:**\n",
    "\n",
    "   ```python\n",
    "   Y_train = train['label']\n",
    "   ```\n",
    "\n",
    "   Here, `train` is a DataFrame containing the MNIST training data. The 'label' column represents the digit (0-9) that each image in the dataset corresponds to. This line extracts the labels from the 'label' column and stores them in `Y_train`.\n",
    "\n",
    "2. **Dropping the Label Column:**\n",
    "\n",
    "   ```python\n",
    "   X_train = train.drop(labels=['label'],axis=1)\n",
    "   ```\n",
    "\n",
    "   This line removes the 'label' column from the `train` DataFrame, leaving only the pixel data of the images. `X_train` now contains only the feature data (pixel values) of the images, without the labels.\n",
    "\n",
    "3. **Freeing Up Memory:**\n",
    "\n",
    "   ```python\n",
    "   del train\n",
    "   ```\n",
    "\n",
    "   This line deletes the `train` DataFrame to free up some memory. After extracting the labels and features, the original `train` DataFrame is no longer needed, so it is removed from memory.\n",
    "\n",
    "4. **Visualizing the Distribution of Labels:**\n",
    "\n",
    "   ```python\n",
    "   graph = sns.countplot(Y_train)\n",
    "   ```\n",
    "\n",
    "   This line uses Seaborn to create a count plot of the `Y_train` labels. This helps visualize the distribution of different digits (0-9) in the training set. \n",
    "\n",
    "5. **Counting the Occurrences of Each Label:**\n",
    "\n",
    "   ```python\n",
    "   Y_train.value_counts()\n",
    "   ```\n",
    "\n",
    "   This line counts the occurrences of each digit in the `Y_train` labels. It returns a Series with the counts of each unique label value, which helps to verify the balance of the dataset.\n",
    "\n",
    "### Context in Building a CNN Model\n",
    "\n",
    "In the context of building a CNN model for the MNIST dataset, these steps are part of the data preprocessing stage. \n",
    "\n",
    "- **Extracting and Separating Data:** The first two steps ensure that the labels (target variable) and the pixel values (features) are separated for further processing.\n",
    "- **Freeing Memory:** The deletion of the original DataFrame helps manage memory usage, which can be crucial when working with large datasets.\n",
    "- **Visualization and Analysis:** Visualizing the label distribution and counting the occurrences help in understanding the dataset better. It can reveal whether the dataset is balanced or if there are any biases in the data, which can affect the training process.\n",
    "\n",
    "After these steps, the next steps would typically involve normalizing the pixel values, reshaping the data to fit the input shape required by the CNN, and then defining and training the CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16be81",
   "metadata": {
    "papermill": {
     "duration": 0.014875,
     "end_time": "2024-06-30T14:52:17.047570",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.032695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72954b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:17.081228Z",
     "iopub.status.busy": "2024-06-30T14:52:17.079765Z",
     "iopub.status.idle": "2024-06-30T14:52:17.125106Z",
     "shell.execute_reply": "2024-06-30T14:52:17.123771Z"
    },
    "papermill": {
     "duration": 0.065199,
     "end_time": "2024-06-30T14:52:17.128015",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.062816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for any null or missing values\n",
    "X_train.isnull().any().describe()\n",
    "\n",
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2938975",
   "metadata": {
    "papermill": {
     "duration": 0.015664,
     "end_time": "2024-06-30T14:52:17.159942",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.144278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0338ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:17.193468Z",
     "iopub.status.busy": "2024-06-30T14:52:17.193021Z",
     "iopub.status.idle": "2024-06-30T14:52:17.342790Z",
     "shell.execute_reply": "2024-06-30T14:52:17.341597Z"
    },
    "papermill": {
     "duration": 0.170245,
     "end_time": "2024-06-30T14:52:17.346051",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.175806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "test = test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ae529",
   "metadata": {
    "papermill": {
     "duration": 0.015554,
     "end_time": "2024-06-30T14:52:17.377509",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.361955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Code Explanation\n",
    "\n",
    "1. **Normalizing Training Data:**\n",
    "\n",
    "   ```python\n",
    "   X_train = X_train / 255\n",
    "   ```\n",
    "\n",
    "   Here, `X_train` contains the pixel values of the training images. The pixel values in the MNIST dataset range from 0 to 255. By dividing each pixel value by 255, the values are scaled to a range between 0 and 1. This normalization step is important for several reasons:\n",
    "   - **Improved Convergence:** Normalizing the input data can help the neural network converge faster during training.\n",
    "   - **Stability:** It helps in maintaining numerical stability in the calculations performed by the network.\n",
    "   - **Consistency:** Ensures that all input features (pixel values) are on the same scale.\n",
    "\n",
    "2. **Normalizing Test Data:**\n",
    "\n",
    "   ```python\n",
    "   test = test / 255\n",
    "   ```\n",
    "\n",
    "   Similarly, this line normalizes the pixel values in the test dataset. `test` contains the pixel values of the images in the test set. Like the training data, the pixel values are scaled to a range between 0 and 1.\n",
    "\n",
    "### Why Normalization is Important in CNNs\n",
    "\n",
    "Normalization is a common preprocessing step in training machine learning models, especially neural networks, for the following reasons:\n",
    "\n",
    "- **Faster Training:** When the input features are normalized, gradient descent can converge more quickly because the gradients are more uniform.\n",
    "- **Better Performance:** Models often perform better when the input data is normalized, as it helps avoid issues with varying scales of input features.\n",
    "- **Prevents Saturation:** For certain activation functions (like sigmoid or tanh), normalization helps prevent the saturation of neurons, where they output values that are too high or too low, making the gradients vanish or explode.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of building a CNN model for the MNIST dataset, these normalization steps ensure that the pixel values of the images are in a suitable range for the neural network to process effectively. This preprocessing step is typically followed by reshaping the data to fit the input dimensions required by the CNN layers (e.g., adding channel dimensions) and then feeding the normalized data into the CNN for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb94e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:17.412677Z",
     "iopub.status.busy": "2024-06-30T14:52:17.411748Z",
     "iopub.status.idle": "2024-06-30T14:52:17.419720Z",
     "shell.execute_reply": "2024-06-30T14:52:17.417761Z"
    },
    "papermill": {
     "duration": 0.029058,
     "end_time": "2024-06-30T14:52:17.422485",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.393427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78894165",
   "metadata": {
    "papermill": {
     "duration": 0.015635,
     "end_time": "2024-06-30T14:52:17.454568",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.438933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet is reshaping the data to fit the input requirements of a Convolutional Neural Network (CNN).\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **Reshaping Training Data:**\n",
    "\n",
    "   ```python\n",
    "   X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "   ```\n",
    "\n",
    "   Here, `X_train` contains the normalized pixel values of the training images. The `values` attribute of a DataFrame returns a NumPy array representation of the DataFrame. The `reshape` method is then used to change the shape of this array.\n",
    "\n",
    "   - `-1`: This means that the dimension is inferred from the length of the array and the remaining dimensions specified. Essentially, it computes the correct size for this dimension so that the total size of the array remains unchanged.\n",
    "   - `28, 28`: The MNIST images are 28x28 pixels.\n",
    "   - `1`: This represents the number of channels. For grayscale images, there is only one channel. For colored images, this number would be 3 (representing RGB channels).\n",
    "\n",
    "   After reshaping, `X_train` will have the shape `(number_of_images, 28, 28, 1)`, which is the format expected by CNNs in many deep learning frameworks like TensorFlow and Keras.\n",
    "\n",
    "2. **Reshaping Test Data:**\n",
    "\n",
    "   ```python\n",
    "   test = test.values.reshape(-1, 28, 28, 1)\n",
    "   ```\n",
    "\n",
    "   Similarly, this line reshapes the `test` data. The process is the same as with the training data. The `test` array, which contains the normalized pixel values of the test images, is reshaped to have the shape `(number_of_images, 28, 28, 1)`.\n",
    "\n",
    "### Why Reshaping is Necessary for CNNs\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are designed to work with multi-dimensional data, especially image data that has spatial dimensions (height and width) and a depth dimension (channels). The required input shape for CNNs typically includes:\n",
    "\n",
    "- **Batch size:** Number of images processed together in one forward/backward pass.\n",
    "- **Height and Width:** Dimensions of each image (28x28 for MNIST).\n",
    "- **Channels:** Number of color channels per image (1 for grayscale, 3 for RGB).\n",
    "\n",
    "By reshaping the data to `(number_of_images, 28, 28, 1)`, you ensure that each image is correctly formatted with height, width, and channel dimensions, making it suitable for the convolutional layers of the network.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of building a CNN model for the MNIST dataset, these reshaping steps are crucial because:\n",
    "\n",
    "1. **Compatibility:** CNN layers require inputs to be in specific shapes to perform convolutions and pooling operations correctly.\n",
    "2. **Efficient Computation:** Properly shaped data ensures that the computational graph is optimized for the operations performed by the CNN.\n",
    "3. **Accurate Modeling:** Ensures that the spatial structure of the image data is preserved, allowing the CNN to effectively learn spatial hierarchies and patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263b0ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:17.487773Z",
     "iopub.status.busy": "2024-06-30T14:52:17.487206Z",
     "iopub.status.idle": "2024-06-30T14:52:17.497169Z",
     "shell.execute_reply": "2024-06-30T14:52:17.495783Z"
    },
    "papermill": {
     "duration": 0.030306,
     "end_time": "2024-06-30T14:52:17.500306",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.470000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec175ba",
   "metadata": {
    "papermill": {
     "duration": 0.01577,
     "end_time": "2024-06-30T14:52:17.533029",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.517259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet converts the labels of the training data into a one-hot encoded format, which is a common preprocessing step when working with categorical data in neural networks. Let's break it down:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=10)\n",
    "```\n",
    "\n",
    "- **`tf.keras.utils.to_categorical`:** This is a utility function provided by TensorFlow's Keras API. It converts a class vector (integers) into a binary class matrix (one-hot encoding).\n",
    "\n",
    "- **`Y_train`:** This is the array containing the labels of the training data. In the context of the MNIST dataset, each label is an integer between 0 and 9, representing the digit in the image.\n",
    "\n",
    "- **`num_classes=10`:** This specifies the number of classes. For the MNIST dataset, there are 10 possible classes (digits 0 through 9).\n",
    "\n",
    "### What is One-Hot Encoding?\n",
    "\n",
    "One-hot encoding is a process that converts categorical labels into a format that can be provided to machine learning algorithms to do a better job in prediction. \n",
    "\n",
    "For example, if `Y_train` contains the labels `[1, 0, 3, 9]`, after one-hot encoding with `num_classes=10`, it will be transformed into:\n",
    "\n",
    "```\n",
    "[\n",
    " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # label 1\n",
    " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # label 0\n",
    " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # label 3\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   # label 9\n",
    "]\n",
    "```\n",
    "\n",
    "Each label is converted into a binary vector of length equal to the number of classes, where the index corresponding to the class is set to 1 and all other indices are set to 0.\n",
    "\n",
    "### Why One-Hot Encoding is Important in CNNs\n",
    "\n",
    "- **Compatibility with Loss Functions:** Many loss functions, such as categorical cross-entropy, expect the target labels to be in a one-hot encoded format.\n",
    "- **Avoids Ordinal Relationships:** One-hot encoding ensures that the model does not assume any ordinal relationship between categories. In the case of MNIST, it prevents the model from interpreting the digits as having a numerical order that might affect the learning process.\n",
    "- **Efficient Computation:** One-hot encoded vectors make it easier to compute the loss and perform the backpropagation step during training.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of building a CNN model for the MNIST dataset, converting the labels to one-hot encoded format is a crucial step. This ensures that the labels are in a suitable format for the output layer of the CNN, which typically uses a softmax activation function for multi-class classification. The softmax function outputs a probability distribution over the classes, and the one-hot encoded labels provide a clear target for computing the loss during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c29525",
   "metadata": {
    "papermill": {
     "duration": 0.015271,
     "end_time": "2024-06-30T14:52:17.564112",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.548841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf58916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:17.598512Z",
     "iopub.status.busy": "2024-06-30T14:52:17.596935Z",
     "iopub.status.idle": "2024-06-30T14:52:18.259742Z",
     "shell.execute_reply": "2024-06-30T14:52:18.258289Z"
    },
    "papermill": {
     "duration": 0.68329,
     "end_time": "2024-06-30T14:52:18.262891",
     "exception": false,
     "start_time": "2024-06-30T14:52:17.579601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Spliting Train and test set\n",
    "random_seed =2\n",
    "\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size=0.1,random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf1013",
   "metadata": {
    "papermill": {
     "duration": 0.015996,
     "end_time": "2024-06-30T14:52:18.294955",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.278959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet splits the training data into a new training set and a validation set.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **Setting a Random Seed:**\n",
    "\n",
    "   ```python\n",
    "   random_seed = 2\n",
    "   ```\n",
    "\n",
    "   A random seed ensures reproducibility. By setting `random_seed` to a specific value, you ensure that the random processes in the code (like shuffling and splitting the data) produce the same results each time you run the code. This is useful for debugging and comparing results consistently.\n",
    "\n",
    "2. **Splitting the Data:**\n",
    "\n",
    "   ```python\n",
    "   X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=random_seed)\n",
    "   ```\n",
    "\n",
    "   - **`train_test_split`:** This function from the `sklearn.model_selection` module splits arrays or matrices into random train and test subsets.\n",
    "   - **`X_train`:** The feature data (pixel values) for the training set before the split.\n",
    "   - **`Y_train`:** The labels for the training set before the split.\n",
    "   - **`test_size=0.1`:** This specifies that 10% of the data should be set aside for validation. Therefore, 90% of the data will remain in the new training set.\n",
    "   - **`random_state=random_seed`:** Ensures the split is reproducible by setting the seed for the random number generator.\n",
    "\n",
    "After this operation, the data is split as follows:\n",
    "- **`X_train`:** 90% of the original training feature data, which will be used to train the model.\n",
    "- **`X_val`:** 10% of the original training feature data, which will be used to validate the model during training.\n",
    "- **`Y_train`:** 90% of the original training labels, corresponding to `X_train`.\n",
    "- **`Y_val`:** 10% of the original training labels, corresponding to `X_val`.\n",
    "\n",
    "### Why Splitting Data is Important\n",
    "\n",
    "- **Validation Set:** Having a separate validation set helps in evaluating the model's performance during training. By validating the model on unseen data, you can get a better estimate of how well the model generalizes to new data.\n",
    "- **Hyperparameter Tuning:** The validation set can be used to tune hyperparameters, such as learning rate, batch size, and the architecture of the model, without affecting the test set.\n",
    "- **Avoid Overfitting:** By monitoring the validation performance, you can detect overfitting early. If the model performs well on the training set but poorly on the validation set, it indicates that the model is overfitting to the training data.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of building a CNN model for the MNIST dataset, splitting the data into training and validation sets is crucial for:\n",
    "\n",
    "1. **Model Evaluation:** The validation set provides an unbiased evaluation of the model during the training phase.\n",
    "2. **Model Selection:** Helps in selecting the best model architecture and hyperparameters by comparing performance on the validation set.\n",
    "3. **Improving Generalization:** Ensures that the model is capable of generalizing well to new, unseen data by preventing overfitting.\n",
    "\n",
    "By splitting the data appropriately, you ensure that the CNN model is trained effectively and its performance is evaluated accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e533ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:18.328781Z",
     "iopub.status.busy": "2024-06-30T14:52:18.328268Z",
     "iopub.status.idle": "2024-06-30T14:52:18.634478Z",
     "shell.execute_reply": "2024-06-30T14:52:18.632956Z"
    },
    "papermill": {
     "duration": 0.326626,
     "end_time": "2024-06-30T14:52:18.637595",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.310969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc190c",
   "metadata": {
    "papermill": {
     "duration": 0.016037,
     "end_time": "2024-06-30T14:52:18.670480",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.654443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ab55fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:18.705265Z",
     "iopub.status.busy": "2024-06-30T14:52:18.704776Z",
     "iopub.status.idle": "2024-06-30T14:52:18.935601Z",
     "shell.execute_reply": "2024-06-30T14:52:18.934054Z"
    },
    "papermill": {
     "duration": 0.252178,
     "end_time": "2024-06-30T14:52:18.938884",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.686706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
    "                       activation=tf.nn.relu, input_shape = (28,28,1)))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
    "                       activation=tf.nn.relu))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
    "                       activation=tf.nn.relu, input_shape = (28,28,1)))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
    "                       activation=tf.nn.relu))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation=tf.nn.relu))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dc3a5",
   "metadata": {
    "papermill": {
     "duration": 0.01853,
     "end_time": "2024-06-30T14:52:18.976341",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.957811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a Convolutional Neural Network (CNN) model using TensorFlow's Keras API for image classification tasks on the MNIST dataset. Let's break it down step by step:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **Model Initialization:**\n",
    "\n",
    "   ```python\n",
    "   model = tf.keras.Sequential()\n",
    "   ```\n",
    "\n",
    "   This initializes a Sequential model. A Sequential model is a linear stack of layers, meaning that you can add layers one by one in a sequential order.\n",
    "\n",
    "2. **First Convolutional Block:**\n",
    "\n",
    "   ```python\n",
    "   model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
    "                           activation=tf.nn.relu, input_shape=(28,28,1)))\n",
    "   model.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n",
    "                           activation=tf.nn.relu))\n",
    "   model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "   model.add(layers.Dropout(0.25))\n",
    "   ```\n",
    "\n",
    "   - **Conv2D Layer:** The first convolutional layer has 32 filters, each of size 5x5, and uses the ReLU activation function. `padding='Same'` means the output feature map will have the same width and height as the input.\n",
    "   - **Conv2D Layer:** The second convolutional layer is similar to the first one with 32 filters and 5x5 kernel size, also using ReLU activation.\n",
    "   - **MaxPool2D Layer:** A max-pooling layer with a pool size of 2x2. This reduces the spatial dimensions of the feature map by half, which helps in reducing the computational load and helps in capturing the most important features.\n",
    "   - **Dropout Layer:** A dropout layer with a rate of 0.25, which means 25% of the neurons will be randomly set to zero during each training step. This helps in preventing overfitting.\n",
    "\n",
    "3. **Second Convolutional Block:**\n",
    "\n",
    "   ```python\n",
    "   model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
    "                           activation=tf.nn.relu))\n",
    "   model.add(layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', \n",
    "                           activation=tf.nn.relu))\n",
    "   model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "   model.add(layers.Dropout(0.25))\n",
    "   ```\n",
    "\n",
    "   - **Conv2D Layer:** The first convolutional layer in this block has 64 filters with a 3x3 kernel size and ReLU activation.\n",
    "   - **Conv2D Layer:** The second convolutional layer is similar to the first one with 64 filters and 3x3 kernel size, also using ReLU activation.\n",
    "   - **MaxPool2D Layer:** A max-pooling layer with a pool size of 2x2 and strides of 2x2, further reducing the spatial dimensions of the feature map.\n",
    "   - **Dropout Layer:** A dropout layer with a rate of 0.25, similar to the previous dropout layer.\n",
    "\n",
    "4. **Fully Connected Layers:**\n",
    "\n",
    "   ```python\n",
    "   model.add(layers.Flatten())\n",
    "   model.add(layers.Dense(256, activation=tf.nn.relu))\n",
    "   model.add(layers.Dropout(0.25))\n",
    "   model.add(layers.Dense(10, activation=tf.nn.softmax))\n",
    "   ```\n",
    "\n",
    "   - **Flatten Layer:** Flattens the input, converting the 2D matrix into a 1D vector, which can be fed into a fully connected (dense) layer.\n",
    "   - **Dense Layer:** A fully connected layer with 256 neurons and ReLU activation.\n",
    "   - **Dropout Layer:** Another dropout layer with a rate of 0.25 to prevent overfitting.\n",
    "   - **Dense Layer:** The output layer with 10 neurons (one for each class in the MNIST dataset) and softmax activation, which outputs a probability distribution over the 10 classes.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Input Shape:** The input shape of the model is `(28, 28, 1)`, matching the dimensions of the MNIST images (28x28 pixels, 1 channel for grayscale).\n",
    "- **Conv2D Layers:** Apply convolution operations to extract spatial features.\n",
    "- **MaxPool2D Layers:** Reduce the spatial dimensions to make the computation more efficient and to capture the most important features.\n",
    "- **Dropout Layers:** Help prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
    "- **Dense Layers:** Fully connected layers that interpret the extracted features to perform classification.\n",
    "- **Softmax Output Layer:** Produces a probability distribution over the 10 classes, useful for multi-class classification tasks like MNIST.\n",
    "\n",
    "This architecture combines convolutional layers for feature extraction and fully connected layers for classification, making it a suitable and effective CNN model for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594a96b",
   "metadata": {
    "papermill": {
     "duration": 0.020834,
     "end_time": "2024-06-30T14:52:19.017588",
     "exception": false,
     "start_time": "2024-06-30T14:52:18.996754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Selecting Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba45e182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.058054Z",
     "iopub.status.busy": "2024-06-30T14:52:19.057487Z",
     "iopub.status.idle": "2024-06-30T14:52:19.065693Z",
     "shell.execute_reply": "2024-06-30T14:52:19.064323Z"
    },
    "papermill": {
     "duration": 0.03292,
     "end_time": "2024-06-30T14:52:19.068359",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.035439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining Optimizer\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4acde8",
   "metadata": {
    "papermill": {
     "duration": 0.015725,
     "end_time": "2024-06-30T14:52:19.100104",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.084379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet defines an optimizer for training a neural network using TensorFlow's Keras API. In this case, the optimizer is RMSprop (Root Mean Square Propagation). Let's break down each component:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "```\n",
    "\n",
    "- **`tf.keras.optimizers.RMSprop`:** This initializes an RMSprop optimizer instance. RMSprop is a popular optimization algorithm used in training neural networks. It adjusts the learning rate for each parameter based on the average of recent magnitudes of the gradients (running average of the squared gradients).\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "1. **`learning_rate=0.001`:**\n",
    "   - **Definition:** The learning rate determines the size of the steps the optimizer takes during each iteration of training.\n",
    "   - **Value:** `0.001` is a common starting point for the learning rate. It controls how quickly the model learns. A smaller value makes the learning process more stable but slower, while a larger value can speed up learning but may cause instability.\n",
    "\n",
    "2. **`rho=0.9`:**\n",
    "   - **Definition:** The `rho` parameter is the decay factor used to calculate the moving average of the squared gradients.\n",
    "   - **Value:** `0.9` means that the moving average of squared gradients is given a weight of `0.9`, and the remaining `0.1` comes from the current squared gradient. This helps in smoothing the gradient updates.\n",
    "\n",
    "3. **`epsilon=1e-08`:**\n",
    "   - **Definition:** The `epsilon` parameter is a small constant added to avoid division by zero during the optimization process.\n",
    "   - **Value:** `1e-08` ensures numerical stability when dividing by the moving average of squared gradients.\n",
    "\n",
    "4. **`decay=0.0`:**\n",
    "   - **Definition:** The `decay` parameter is used to apply decay to the learning rate over time.\n",
    "   - **Value:** `0.0` means that no decay is applied to the learning rate. If `decay` were set to a positive value, the learning rate would decrease over time according to the decay rate.\n",
    "\n",
    "### How RMSprop Works\n",
    "\n",
    "RMSprop is designed to overcome some of the problems of standard gradient descent and its variants, such as:\n",
    "\n",
    "- **Adaptive Learning Rates:** RMSprop adapts the learning rate for each parameter individually based on the average of recent squared gradients. This helps in managing the learning rate more effectively for each parameter, which is particularly useful for dealing with noisy gradients and varying gradient magnitudes.\n",
    "- **Stabilizes Training:** By adjusting the learning rate for each parameter, RMSprop helps stabilize the training process, especially in scenarios where gradients are sparse or have large variance.\n",
    "\n",
    "### Context in Building a CNN Model\n",
    "\n",
    "In the context of building and training a Convolutional Neural Network (CNN) for the MNIST dataset or any other image classification task:\n",
    "\n",
    "- **Optimizer Choice:** RMSprop is chosen for its ability to adaptively adjust learning rates, which can be beneficial for complex models and datasets with varying gradient scales.\n",
    "- **Learning Rate Management:** Proper configuration of the learning rate and other parameters is crucial for effective model training. RMSprops adaptive learning rates help the model converge more efficiently and potentially avoid issues like slow convergence or divergence.\n",
    "- **Stability:** RMSprop's use of moving averages for gradient magnitudes helps to provide more stable updates and can lead to better performance in training deep neural networks.\n",
    "\n",
    "By defining this optimizer, you are preparing the CNN model to use RMSprop for optimizing the weights during training, aiming for efficient and stable learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86ac37e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.136021Z",
     "iopub.status.busy": "2024-06-30T14:52:19.135298Z",
     "iopub.status.idle": "2024-06-30T14:52:19.160052Z",
     "shell.execute_reply": "2024-06-30T14:52:19.158279Z"
    },
    "papermill": {
     "duration": 0.046549,
     "end_time": "2024-06-30T14:52:19.163564",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.117015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece00932",
   "metadata": {
    "papermill": {
     "duration": 0.017038,
     "end_time": "2024-06-30T14:52:19.202048",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.185010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet compiles the CNN model using TensorFlow's Keras API. Compiling a model is an essential step before training, as it configures the model with the optimizer, loss function, and evaluation metrics. Lets break down each component:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "- **`optimizer=optimizer`:**\n",
    "  - **Definition:** This parameter specifies the optimization algorithm to be used during training. In this case, it uses the `optimizer` object defined previously, which is an instance of the RMSprop optimizer.\n",
    "  - **Purpose:** The optimizer updates the models weights based on the gradients computed during backpropagation to minimize the loss function.\n",
    "\n",
    "- **`loss='categorical_crossentropy'`:**\n",
    "  - **Definition:** This parameter specifies the loss function to be used. `categorical_crossentropy` is a loss function suitable for multi-class classification problems where the labels are one-hot encoded.\n",
    "  - **Purpose:** The loss function measures how well the model's predictions match the true labels. During training, the model aims to minimize this loss. For the MNIST dataset, where each label is one-hot encoded (i.e., a vector with a single `1` and the rest `0`), `categorical_crossentropy` is appropriate because it computes the cross-entropy loss between the true labels and predicted probabilities.\n",
    "\n",
    "- **`metrics=[\"accuracy\"]`:**\n",
    "  - **Definition:** This parameter specifies the metrics to be evaluated during training and testing. Here, `accuracy` is used as the metric.\n",
    "  - **Purpose:** Metrics are used to monitor the performance of the model. `accuracy` measures the percentage of correctly classified images out of the total number of images. During training, Keras will report the accuracy of the model on both the training and validation sets (if a validation set is provided).\n",
    "\n",
    "### Why Compilation is Important\n",
    "\n",
    "1. **Optimizer Configuration:** The optimizer defines how the models weights are updated based on the gradients. Proper configuration of the optimizer is crucial for effective training.\n",
    "\n",
    "2. **Loss Function Selection:** The loss function quantifies the difference between the model's predictions and the true values. Choosing the appropriate loss function is essential for guiding the training process in the right direction.\n",
    "\n",
    "3. **Metrics Monitoring:** Metrics provide insights into the models performance and help in understanding how well the model is learning. They are useful for tracking progress during training and for evaluating the model's performance on validation or test data.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of building and training a CNN model for the MNIST dataset:\n",
    "\n",
    "- **Optimizer (RMSprop):** RMSprop is chosen for its adaptive learning rate capabilities, which helps in training deep networks by adjusting learning rates for each parameter.\n",
    "- **Loss Function (Categorical Cross-Entropy):** Since MNIST is a multi-class classification problem with one-hot encoded labels, categorical cross-entropy is suitable for measuring how well the model's predicted probabilities align with the true labels.\n",
    "- **Metric (Accuracy):** Accuracy is a straightforward and useful metric for evaluating the performance of the model on classification tasks. It provides a clear indication of how well the model is performing in terms of correct classifications.\n",
    "\n",
    "By compiling the model with these settings, you prepare it for training with the chosen optimizer, loss function, and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b113702",
   "metadata": {
    "papermill": {
     "duration": 0.016666,
     "end_time": "2024-06-30T14:52:19.234603",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.217937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setting Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b596040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.268359Z",
     "iopub.status.busy": "2024-06-30T14:52:19.267928Z",
     "iopub.status.idle": "2024-06-30T14:52:19.274807Z",
     "shell.execute_reply": "2024-06-30T14:52:19.273200Z"
    },
    "papermill": {
     "duration": 0.027274,
     "end_time": "2024-06-30T14:52:19.277752",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.250478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting Learning rate\n",
    "\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7d3e5",
   "metadata": {
    "papermill": {
     "duration": 0.015735,
     "end_time": "2024-06-30T14:52:19.309889",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.294154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code sets up a callback for adjusting the learning rate during training based on the model's performance on the validation set. The callback is `ReduceLROnPlateau`, which is part of TensorFlow's Keras API. Let's break down each component:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "```\n",
    "\n",
    "- **`tf.keras.callbacks.ReduceLROnPlateau`:**\n",
    "  - **Definition:** This callback monitors a specified metric and reduces the learning rate when the metric stops improving. It's useful for adjusting the learning rate dynamically based on the training process to help the model converge better.\n",
    "  - **Purpose:** Helps in fine-tuning the learning rate to improve model performance and training efficiency, especially if the model's performance plateaus.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **`monitor='val_acc'`:**\n",
    "   - **Definition:** The metric to monitor for deciding when to reduce the learning rate.\n",
    "   - **Purpose:** `'val_acc'` (or `val_accuracy` in newer versions of TensorFlow) indicates that the callback will monitor the validation accuracy. When validation accuracy stops improving, the learning rate will be reduced.\n",
    "   - **Note:** Depending on the TensorFlow/Keras version, the metric might be `'val_accuracy'` rather than `'val_acc'`.\n",
    "\n",
    "2. **`patience=3`:**\n",
    "   - **Definition:** The number of epochs with no improvement after which the learning rate will be reduced.\n",
    "   - **Purpose:** If the validation accuracy does not improve for 3 consecutive epochs, the learning rate will be reduced. This helps to prevent premature learning rate adjustments and ensures that the model has enough epochs to show improvement before reducing the learning rate.\n",
    "\n",
    "3. **`verbose=1`:**\n",
    "   - **Definition:** Controls the verbosity mode. `verbose=1` means that the callback will print messages when the learning rate is reduced.\n",
    "   - **Purpose:** Provides feedback during training about when and how the learning rate is adjusted, which can be useful for monitoring the training process.\n",
    "\n",
    "4. **`factor=0.5`:**\n",
    "   - **Definition:** The factor by which the learning rate will be reduced.\n",
    "   - **Purpose:** When the learning rate is reduced, it will be multiplied by 0.5. For example, if the current learning rate is 0.001, it will be reduced to 0.0005.\n",
    "\n",
    "5. **`min_lr=0.00001`:**\n",
    "   - **Definition:** The minimum learning rate allowed.\n",
    "   - **Purpose:** Ensures that the learning rate does not fall below 0.00001, which prevents the learning rate from becoming too small and potentially causing training to stall.\n",
    "\n",
    "### Why ReduceLROnPlateau is Useful\n",
    "\n",
    "- **Dynamic Adjustment:** It allows the learning rate to be adjusted based on the model's performance during training, rather than using a fixed learning rate. This can help in achieving better convergence and avoiding overshooting minima.\n",
    "- **Improved Performance:** Reducing the learning rate when the model's performance plateaus can help in fine-tuning the model and improving its final performance.\n",
    "- **Training Efficiency:** Helps in making the most out of the available training epochs by dynamically adjusting the learning rate to ensure continued progress.\n",
    "\n",
    "### Context in Building a CNN Model for MNIST\n",
    "\n",
    "In the context of training a CNN model for the MNIST dataset:\n",
    "\n",
    "- **Monitoring Validation Accuracy:** By monitoring validation accuracy, you ensure that the learning rate is adjusted based on how well the model generalizes to unseen data, rather than just fitting to the training data.\n",
    "- **Adaptive Learning Rate:** This callback helps in adapting the learning rate to the training dynamics, which can be particularly useful if the model's performance improvement slows down during training.\n",
    "- **Preventing Overfitting:** Dynamic adjustment of the learning rate can also help in reducing overfitting by allowing the model to continue learning effectively even when the performance on the validation set plateaus.\n",
    "\n",
    "By setting up this callback, you enhance the training process of your CNN model, allowing it to adaptively adjust the learning rate for potentially better training outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc8d0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.345296Z",
     "iopub.status.busy": "2024-06-30T14:52:19.344663Z",
     "iopub.status.idle": "2024-06-30T14:52:19.358422Z",
     "shell.execute_reply": "2024-06-30T14:52:19.356812Z"
    },
    "papermill": {
     "duration": 0.035892,
     "end_time": "2024-06-30T14:52:19.361554",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.325662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3f084",
   "metadata": {
    "papermill": {
     "duration": 0.015328,
     "end_time": "2024-06-30T14:52:19.392481",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.377153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30d2f8b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.426879Z",
     "iopub.status.busy": "2024-06-30T14:52:19.426180Z",
     "iopub.status.idle": "2024-06-30T14:52:19.590865Z",
     "shell.execute_reply": "2024-06-30T14:52:19.589572Z"
    },
    "papermill": {
     "duration": 0.186746,
     "end_time": "2024-06-30T14:52:19.594963",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.408217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False, \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False, \n",
    "        vertical_flip=False)  \n",
    "\n",
    "model1.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95614779",
   "metadata": {
    "papermill": {
     "duration": 0.015573,
     "end_time": "2024-06-30T14:52:19.630578",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.615005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet sets up an `ImageDataGenerator` for data augmentation and then attempts to fit a model using this generator. Let's break it down in detail:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### ImageDataGenerator Configuration\n",
    "\n",
    "```python\n",
    "model1 = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images horizontally\n",
    "    vertical_flip=False)  # randomly flip images vertically\n",
    "```\n",
    "\n",
    "- **`ImageDataGenerator`:** This is a Keras utility that allows you to generate batches of tensor image data with real-time data augmentation. This is useful for improving model generalization by creating variations of the training data.\n",
    "\n",
    "##### Parameters:\n",
    "\n",
    "1. **`featurewise_center=False`:**\n",
    "   - **Definition:** When `True`, it subtracts the mean of the dataset from each image, making the average pixel value 0.\n",
    "   - **Purpose:** Helps in normalizing the input data, but here it is turned off.\n",
    "\n",
    "2. **`samplewise_center=False`:**\n",
    "   - **Definition:** When `True`, it subtracts the mean of each image from itself, making the mean of each image 0.\n",
    "   - **Purpose:** Normalizes each sample individually, but here it is turned off.\n",
    "\n",
    "3. **`featurewise_std_normalization=False`:**\n",
    "   - **Definition:** When `True`, it divides each image by the standard deviation of the dataset.\n",
    "   - **Purpose:** Normalizes the dataset by scaling the features, but it is turned off here.\n",
    "\n",
    "4. **`samplewise_std_normalization=False`:**\n",
    "   - **Definition:** When `True`, it divides each image by its own standard deviation.\n",
    "   - **Purpose:** Scales each sample individually, but it is turned off.\n",
    "\n",
    "5. **`zca_whitening=False`:**\n",
    "   - **Definition:** When `True`, it applies ZCA (Zero Component Analysis) whitening to the images.\n",
    "   - **Purpose:** Helps in decorrelating and normalizing the input features, but it is turned off.\n",
    "\n",
    "6. **`rotation_range=10`:**\n",
    "   - **Definition:** Specifies the range (in degrees) for random rotations.\n",
    "   - **Purpose:** Randomly rotates images by up to 10 degrees to make the model invariant to small rotations.\n",
    "\n",
    "7. **`zoom_range=0.1`:**\n",
    "   - **Definition:** Specifies the range for random zoom.\n",
    "   - **Purpose:** Randomly zooms in or out of the image by up to 10% to improve robustness to zoom variations.\n",
    "\n",
    "8. **`width_shift_range=0.1`:**\n",
    "   - **Definition:** Specifies the range for random horizontal shifts.\n",
    "   - **Purpose:** Randomly shifts images horizontally by up to 10% of the width to enhance model generalization.\n",
    "\n",
    "9. **`height_shift_range=0.1`:**\n",
    "   - **Definition:** Specifies the range for random vertical shifts.\n",
    "   - **Purpose:** Randomly shifts images vertically by up to 10% of the height to improve robustness to vertical shifts.\n",
    "\n",
    "10. **`horizontal_flip=False`:**\n",
    "    - **Definition:** When `True`, it randomly flips images horizontally.\n",
    "    - **Purpose:** Helps in learning invariance to horizontal flipping, but it is turned off here.\n",
    "\n",
    "11. **`vertical_flip=False`:**\n",
    "    - **Definition:** When `True`, it randomly flips images vertically.\n",
    "    - **Purpose:** Helps in learning invariance to vertical flipping, but it is turned off.\n",
    "\n",
    "#### Fitting the Model\n",
    "\n",
    "```python\n",
    "model1.fit(X_train)\n",
    "```\n",
    "\n",
    "- **`model1.fit(X_train)`:** This line is meant to fit the model (which is actually an `ImageDataGenerator`) on the data `X_train`.\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Correct Usage:** `ImageDataGenerator` is typically used with methods like `flow()` or `flow_from_directory()` to generate batches of augmented images. It does not have a `fit()` method itself. Instead, it should be used with a models `fit()` method like this:\n",
    "\n",
    "   ```python\n",
    "   model.fit(model1.flow(X_train, Y_train), epochs=num_epochs)\n",
    "   ```\n",
    "\n",
    "   Here, `model1.flow(X_train, Y_train)` generates batches of augmented images and their corresponding labels for training.\n",
    "\n",
    "- **Purpose of Data Augmentation:** The `ImageDataGenerator` is used to augment the training data in real-time during the training process. This helps in improving the model's ability to generalize by exposing it to variations of the training data.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Data Augmentation:** `ImageDataGenerator` is configured to perform various augmentations such as rotation, zoom, and shifting to enrich the training dataset.\n",
    "- **Normalization and Whitening:** These features are turned off in this setup, meaning no normalization or whitening is applied.\n",
    "- **Model Training:** `ImageDataGenerator` is used for data augmentation, but it should be correctly integrated with the `fit` method of a Keras model to be effective.\n",
    "\n",
    "Ensure to integrate `ImageDataGenerator` properly with your model training process to leverage data augmentation effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d00eb0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T14:52:19.665824Z",
     "iopub.status.busy": "2024-06-30T14:52:19.664124Z",
     "iopub.status.idle": "2024-06-30T15:21:02.868345Z",
     "shell.execute_reply": "2024-06-30T15:21:02.866638Z"
    },
    "papermill": {
     "duration": 1723.225645,
     "end_time": "2024-06-30T15:21:02.872213",
     "exception": false,
     "start_time": "2024-06-30T14:52:19.646568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "295/295 - 85s - loss: 0.4251 - accuracy: 0.8654 - val_loss: 0.0723 - val_accuracy: 0.9779\n",
      "Epoch 2/15\n",
      "295/295 - 84s - loss: 0.1144 - accuracy: 0.9650 - val_loss: 0.0514 - val_accuracy: 0.9857\n",
      "Epoch 3/15\n",
      "295/295 - 83s - loss: 0.0799 - accuracy: 0.9753 - val_loss: 0.0317 - val_accuracy: 0.9898\n",
      "Epoch 4/15\n",
      "295/295 - 84s - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
      "Epoch 5/15\n",
      "295/295 - 85s - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.0340 - val_accuracy: 0.9886\n",
      "Epoch 6/15\n",
      "295/295 - 84s - loss: 0.0532 - accuracy: 0.9839 - val_loss: 0.0264 - val_accuracy: 0.9907\n",
      "Epoch 7/15\n",
      "295/295 - 84s - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.0263 - val_accuracy: 0.9921\n",
      "Epoch 8/15\n",
      "295/295 - 84s - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0220 - val_accuracy: 0.9924\n",
      "Epoch 9/15\n",
      "295/295 - 83s - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.0206 - val_accuracy: 0.9940\n",
      "Epoch 10/15\n",
      "295/295 - 83s - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.0202 - val_accuracy: 0.9943\n",
      "Epoch 11/15\n",
      "295/295 - 84s - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.0192 - val_accuracy: 0.9936\n",
      "Epoch 12/15\n",
      "295/295 - 85s - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0226 - val_accuracy: 0.9931\n",
      "Epoch 13/15\n",
      "295/295 - 83s - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.0200 - val_accuracy: 0.9933\n",
      "Epoch 14/15\n",
      "295/295 - 84s - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.0210 - val_accuracy: 0.9948\n",
      "Epoch 15/15\n",
      "295/295 - 85s - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.0310 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(model1.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7adada",
   "metadata": {
    "papermill": {
     "duration": 0.018262,
     "end_time": "2024-06-30T15:21:02.910552",
     "exception": false,
     "start_time": "2024-06-30T15:21:02.892290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet is used to train a Keras model with data augmentation using the `ImageDataGenerator`. It employs `model.fit_generator` to fit the model on augmented data generated by the `ImageDataGenerator`. Heres a detailed explanation of each component of this code:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "history = model.fit_generator(\n",
    "    model1.flow(X_train, Y_train, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    verbose=2,\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    callbacks=[learning_rate_reduction]\n",
    ")\n",
    "```\n",
    "\n",
    "#### Parameters and Components\n",
    "\n",
    "1. **`model.fit_generator(...)`**:\n",
    "   - **Definition:** `fit_generator` is used to train the model on data generated batch-by-batch by a Python generator or a `tf.keras.utils.ImageDataGenerator` instance. Note that `fit_generator` is deprecated in favor of `model.fit` in newer versions of TensorFlow/Keras, but its still useful in older versions.\n",
    "   - **Purpose:** It allows for training on data that is generated in real-time, which is especially useful for data augmentation.\n",
    "\n",
    "2. **`model1.flow(X_train, Y_train, batch_size=batch_size)`**:\n",
    "   - **Definition:** `model1.flow(...)` is a method of the `ImageDataGenerator` that generates batches of augmented data.\n",
    "   - **Purpose:** It takes the training data `X_train` and labels `Y_train`, and generates augmented batches of data with the specified `batch_size`. The generator produces batches of data in real-time with the augmentations specified in the `ImageDataGenerator`.\n",
    "\n",
    "3. **`epochs=epochs`**:\n",
    "   - **Definition:** The number of epochs to train the model.\n",
    "   - **Purpose:** It specifies how many times the entire training dataset will be passed through the model during training.\n",
    "\n",
    "4. **`validation_data=(X_val, Y_val)`**:\n",
    "   - **Definition:** Tuple of validation data and labels.\n",
    "   - **Purpose:** This data is used to evaluate the model's performance on unseen data after each epoch. It helps in monitoring the models ability to generalize.\n",
    "\n",
    "5. **`verbose=2`**:\n",
    "   - **Definition:** Controls the verbosity of the output during training.\n",
    "   - **Purpose:** `verbose=2` provides a more detailed output, showing progress of training for each epoch.\n",
    "\n",
    "6. **`steps_per_epoch=X_train.shape[0] // batch_size`**:\n",
    "   - **Definition:** Number of steps (batches) to draw from the generator for each epoch.\n",
    "   - **Purpose:** It determines how many batches the model should process before declaring an epoch finished. Its calculated by dividing the number of training samples by the batch size. This ensures that each epoch processes the entire training dataset.\n",
    "\n",
    "7. **`callbacks=[learning_rate_reduction]`**:\n",
    "   - **Definition:** A list of callback functions to apply during training.\n",
    "   - **Purpose:** `learning_rate_reduction` is an instance of `ReduceLROnPlateau`, which dynamically adjusts the learning rate based on the performance of the model. This callback helps in fine-tuning the learning rate to improve convergence.\n",
    "\n",
    "### Summary of Training Process\n",
    "\n",
    "- **Data Generation:** `model1.flow(X_train, Y_train, batch_size=batch_size)` generates batches of augmented training data in real-time. This helps in enhancing model generalization by exposing it to various transformations of the training data.\n",
    "  \n",
    "- **Epochs and Steps:** The model trains for a specified number of epochs. During each epoch, it processes `X_train.shape[0] // batch_size` batches of data.\n",
    "\n",
    "- **Validation:** After each epoch, the models performance is evaluated on the validation set `(X_val, Y_val)`.\n",
    "\n",
    "- **Callbacks:** The `learning_rate_reduction` callback is used to adjust the learning rate dynamically if the validation accuracy plateaus.\n",
    "\n",
    "- **Verbose Output:** `verbose=2` provides detailed logs about the training progress.\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Deprecation:** In newer versions of TensorFlow/Keras, `fit_generator` has been replaced by `fit`, which can also accept data generators directly.\n",
    "\n",
    "- **Integration:** Ensure that `model1` is correctly set up as an `ImageDataGenerator` and that `batch_size` and `epochs` are properly defined variables.\n",
    "\n",
    "By using this setup, you effectively train your model with augmented data and dynamically adjust the learning rate to enhance training efficiency and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70eb7a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T15:21:02.953078Z",
     "iopub.status.busy": "2024-06-30T15:21:02.951582Z",
     "iopub.status.idle": "2024-06-30T15:21:03.503832Z",
     "shell.execute_reply": "2024-06-30T15:21:03.502422Z"
    },
    "papermill": {
     "duration": 0.576695,
     "end_time": "2024-06-30T15:21:03.507116",
     "exception": false,
     "start_time": "2024-06-30T15:21:02.930421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best')\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f1534",
   "metadata": {
    "papermill": {
     "duration": 0.019311,
     "end_time": "2024-06-30T15:21:03.546655",
     "exception": false,
     "start_time": "2024-06-30T15:21:03.527344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet is used to visualize the training and validation performance of a machine learning model by plotting the loss and accuracy curves. It leverages Matplotlib, a popular Python library for plotting, to create two subplots that display these metrics over the training epochs. Heres a detailed breakdown of each component:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "legend = ax[0].legend(loc='best')\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r', label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best')\n",
    "```\n",
    "\n",
    "#### Components:\n",
    "\n",
    "1. **`fig, ax = plt.subplots(2, 1)`**:\n",
    "   - **Definition:** Creates a figure and a set of subplots. In this case, `plt.subplots(2, 1)` creates a figure with 2 subplots arranged vertically (2 rows, 1 column).\n",
    "   - **Purpose:** Sets up the plotting area where the loss and accuracy curves will be drawn. `fig` represents the entire figure, and `ax` is an array containing the two subplot axes.\n",
    "\n",
    "2. **`ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")`**:\n",
    "   - **Definition:** Plots the training loss values on the first subplot (`ax[0]`).\n",
    "   - **Purpose:** Displays how the training loss changes over epochs. The `color='b'` argument sets the line color to blue, and `label=\"Training loss\"` adds a label for the legend.\n",
    "\n",
    "3. **`ax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\")`**:\n",
    "   - **Definition:** Plots the validation loss values on the first subplot (`ax[0]`).\n",
    "   - **Purpose:** Displays how the validation loss changes over epochs. The `color='r'` argument sets the line color to red, and `label=\"Validation loss\"` adds a label for the legend.\n",
    "\n",
    "4. **`legend = ax[0].legend(loc='best')`**:\n",
    "   - **Definition:** Adds a legend to the first subplot (`ax[0]`).\n",
    "   - **Purpose:** `loc='best'` automatically places the legend in the best location on the plot to avoid overlapping with the plotted lines.\n",
    "\n",
    "5. **`ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")`**:\n",
    "   - **Definition:** Plots the training accuracy values on the second subplot (`ax[1]`).\n",
    "   - **Purpose:** Shows how the training accuracy changes over epochs. The `color='b'` argument sets the line color to blue, and `label=\"Training accuracy\"` adds a label for the legend.\n",
    "\n",
    "6. **`ax[1].plot(history.history['val_accuracy'], color='r', label=\"Validation accuracy\")`**:\n",
    "   - **Definition:** Plots the validation accuracy values on the second subplot (`ax[1]`).\n",
    "   - **Purpose:** Displays how the validation accuracy changes over epochs. The `color='r'` argument sets the line color to red, and `label=\"Validation accuracy\"` adds a label for the legend.\n",
    "\n",
    "7. **`legend = ax[1].legend(loc='best')`**:\n",
    "   - **Definition:** Adds a legend to the second subplot (`ax[1]`).\n",
    "   - **Purpose:** `loc='best'` automatically places the legend in the best location on the plot to avoid overlapping with the plotted lines.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Visualization Purpose:** This code creates visualizations of how the training and validation loss and accuracy change over the course of training epochs. This helps in diagnosing how well the model is learning and generalizing.\n",
    "  \n",
    "- **Training Loss vs. Validation Loss:** Plotting both allows you to see if the model is overfitting (i.e., if the training loss decreases while validation loss increases).\n",
    "\n",
    "- **Training Accuracy vs. Validation Accuracy:** Similarly, plotting both training and validation accuracy helps in understanding the models performance and generalization ability.\n",
    "\n",
    "- **Plot Arrangement:** Using `plt.subplots(2, 1)` creates two vertical plots, one for loss and one for accuracy, to easily compare the metrics.\n",
    "\n",
    "### Visualization Insights\n",
    "\n",
    "- **Overfitting or Underfitting:** You can observe if the training loss decreases but validation loss starts increasing (overfitting) or if both losses are high (underfitting).\n",
    "\n",
    "- **Learning Progress:** The accuracy curves show how well the model improves its performance over time. Smooth and increasing curves generally indicate good learning.\n",
    "\n",
    "By plotting these metrics, you can gain valuable insights into the training dynamics of your model and make informed decisions for further adjustments in model architecture or training parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb7b96",
   "metadata": {
    "papermill": {
     "duration": 0.018819,
     "end_time": "2024-06-30T15:21:03.585068",
     "exception": false,
     "start_time": "2024-06-30T15:21:03.566249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Result Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1ca6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T15:21:03.625754Z",
     "iopub.status.busy": "2024-06-30T15:21:03.625235Z",
     "iopub.status.idle": "2024-06-30T15:21:22.893759Z",
     "shell.execute_reply": "2024-06-30T15:21:22.892197Z"
    },
    "papermill": {
     "duration": 19.293912,
     "end_time": "2024-06-30T15:21:22.897992",
     "exception": false,
     "start_time": "2024-06-30T15:21:03.604080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fdc17",
   "metadata": {
    "papermill": {
     "duration": 0.018695,
     "end_time": "2024-06-30T15:21:22.936396",
     "exception": false,
     "start_time": "2024-06-30T15:21:22.917701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet performs predictions using a trained machine learning model, processes the predicted results, and formats them into a suitable format for further use or submission. Lets break down each part of the code:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the index with the maximum probability\n",
    "results = np.argmax(results, axis=1)\n",
    "\n",
    "results = pd.Series(results, name=\"Label\")\n",
    "```\n",
    "\n",
    "#### Detailed Breakdown\n",
    "\n",
    "1. **`results = model.predict(test)`**:\n",
    "   - **Definition:** `model.predict(test)` generates predictions for the input data `test` using the trained model.\n",
    "   - **Purpose:** The `predict` method outputs the models predicted probabilities for each class for the given input data. For classification tasks, this will typically return a 2D array where each row corresponds to a sample and each column corresponds to the probability of that sample belonging to a particular class.\n",
    "\n",
    "2. **`results = np.argmax(results, axis=1)`**:\n",
    "   - **Definition:** `np.argmax(results, axis=1)` finds the index of the maximum value along the specified axis (axis=1 in this case).\n",
    "   - **Purpose:** For each row in the `results` array (which represents each sample), `np.argmax` returns the index of the class with the highest probability. This converts the probability distributions into class predictions. For example, if the model predicts probabilities `[0.1, 0.3, 0.6]` for a sample, `np.argmax` will return `2`, indicating that class 2 has the highest probability.\n",
    "\n",
    "3. **`results = pd.Series(results, name=\"Label\")`**:\n",
    "   - **Definition:** `pd.Series(results, name=\"Label\")` converts the numpy array of predicted class indices into a pandas Series object and names it \"Label\".\n",
    "   - **Purpose:** Converting the predictions into a pandas Series makes it easier to handle and analyze the results, especially if you need to save or manipulate them further. Naming the Series \"Label\" is useful for clarity, especially if you are preparing data for a DataFrame or for submission where the column name \"Label\" is expected.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Model Prediction:** The model predicts probabilities for each class for the input data.\n",
    "- **Class Prediction:** `np.argmax` is used to convert these probabilities into class labels by selecting the index of the maximum probability.\n",
    "- **Format Results:** The predictions are then converted into a pandas Series, which is a common format for data manipulation and analysis in Python.\n",
    "\n",
    "### Example Use Case\n",
    "\n",
    "- **In a Classification Task:** For a dataset like MNIST (handwritten digit classification), where you have 10 classes (digits 0 through 9), this code will produce class labels for each test image based on the models predictions.\n",
    "- **Preparing Submission:** If you are preparing results for submission in a competition or for evaluation, converting predictions into a pandas Series with a name like \"Label\" can be useful for exporting to a CSV file or for further analysis.\n",
    "\n",
    "This code snippet effectively bridges the gap between raw model predictions and a user-friendly format that can be easily interpreted or submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b5362",
   "metadata": {
    "papermill": {
     "duration": 0.01847,
     "end_time": "2024-06-30T15:21:22.974756",
     "exception": false,
     "start_time": "2024-06-30T15:21:22.956286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cec0640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T15:21:23.016399Z",
     "iopub.status.busy": "2024-06-30T15:21:23.015855Z",
     "iopub.status.idle": "2024-06-30T15:21:23.082894Z",
     "shell.execute_reply": "2024-06-30T15:21:23.081455Z"
    },
    "papermill": {
     "duration": 0.092564,
     "end_time": "2024-06-30T15:21:23.086154",
     "exception": false,
     "start_time": "2024-06-30T15:21:22.993590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea888fc",
   "metadata": {
    "papermill": {
     "duration": 0.01882,
     "end_time": "2024-06-30T15:21:23.123899",
     "exception": false,
     "start_time": "2024-06-30T15:21:23.105079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code snippet is used to prepare and save the final predictions of a model to a CSV file, typically for submission in machine learning competitions or evaluations. It combines the predicted labels with a unique identifier for each image and then exports the results to a CSV file. Heres a detailed breakdown of each part:\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "submission = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), results], axis=1)\n",
    "\n",
    "submission.to_csv(\"mnist.csv\", index=False)\n",
    "```\n",
    "\n",
    "#### Detailed Breakdown\n",
    "\n",
    "1. **`pd.Series(range(1, 28001), name=\"ImageId\")`**:\n",
    "   - **Definition:** `pd.Series` creates a pandas Series from the given data. `range(1, 28001)` generates a sequence of numbers from 1 to 28000 (inclusive), and `name=\"ImageId\"` names the Series as \"ImageId\".\n",
    "   - **Purpose:** This Series acts as a unique identifier for each image in the test set. Its used to create a column in the final DataFrame that indicates which image each prediction corresponds to.\n",
    "\n",
    "2. **`pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), results], axis=1)`**:\n",
    "   - **Definition:** `pd.concat` concatenates two or more pandas objects along a specified axis. Here, it concatenates the Series of image IDs with the `results` Series (which contains the predicted labels).\n",
    "   - **Parameters:**\n",
    "     - **`[pd.Series(range(1, 28001), name=\"ImageId\"), results]`:** List of objects to concatenate. The first object is the Series of image IDs, and the second is the Series of predicted labels.\n",
    "     - **`axis=1`:** Specifies that concatenation should occur along the columns (horizontally).\n",
    "   - **Purpose:** This creates a DataFrame where the first column is \"ImageId\" and the second column contains the predicted labels. The `axis=1` argument ensures that the Series are concatenated side by side.\n",
    "\n",
    "3. **`submission.to_csv(\"mnist.csv\", index=False)`**:\n",
    "   - **Definition:** `to_csv` writes the DataFrame `submission` to a CSV file.\n",
    "   - **Parameters:**\n",
    "     - **`\"mnist.csv\"`:** The name of the file to which the DataFrame is saved.\n",
    "     - **`index=False`:** Ensures that the DataFrames index is not included in the CSV file. Only the columns \"ImageId\" and the predicted labels will be written to the file.\n",
    "   - **Purpose:** Saves the DataFrame as a CSV file named \"mnist.csv\". This file can be used for submission in competitions, for further analysis, or for sharing results.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Creating Identifiers:** A Series of image IDs is created to uniquely identify each test sample.\n",
    "- **Combining Results:** The image IDs and the predicted labels are combined into a single DataFrame.\n",
    "- **Saving Results:** The DataFrame is saved to a CSV file, which is a common format for storing and sharing data.\n",
    "\n",
    "### Example Use Case\n",
    "\n",
    "- **Competition Submission:** In a competition like Kaggles MNIST digit classification challenge, submissions usually require a CSV file where each row corresponds to an image ID and its predicted label. This code prepares that file.\n",
    "- **Evaluation:** The CSV file can be used to evaluate model performance on a test set by comparing predictions against ground truth labels.\n",
    "\n",
    "By using this code, you ensure that your models predictions are formatted correctly and saved in a way thats easy to use for evaluations or submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d09761",
   "metadata": {
    "papermill": {
     "duration": 0.01877,
     "end_time": "2024-06-30T15:21:23.162929",
     "exception": false,
     "start_time": "2024-06-30T15:21:23.144159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thank You for Visiting!\n",
    "\n",
    "Thank you so much for taking the time to visit my Kaggle notebook! I hope you found the analysis informative and helpful. Your interest and support mean a lot to me.\n",
    "\n",
    "If you have any questions, suggestions, or feedback, please feel free to leave a comment or reach out to me. Your input is invaluable in helping me improve and grow as a data scientist.\n",
    "\n",
    "Once again, thank you for stopping by! Wishing you all the best in your data science journey.\n",
    "\n",
    "Best regards,\n",
    "\n",
    "Akanksha"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30301,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1778.491214,
   "end_time": "2024-06-30T15:21:25.957586",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-30T14:51:47.466372",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
